{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ml_models import OptimizationModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GPyOpt.methods.modular_bayesian_optimization.ModularBayesianOptimization object at 0x7fc91b0d2fa0>\n",
      "<GPyOpt.acquisitions.EI.AcquisitionEI object at 0x7fc91b0d23a0>\n",
      "1\n",
      "MPI\n",
      "last, <GPyOpt.acquisitions.MPI.AcquisitionMPI object at 0x7fc91992ef70>\n",
      "<GPyOpt.core.evaluators.sequential.Sequential object at 0x7fc8f8d982b0>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m number_of_iterations \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m  \u001b[39m# Define the number of iterations for the learning loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_iterations):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# Suggest next locations for experiments\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     next_locations \u001b[39m=\u001b[39m opt_model\u001b[39m.\u001b[39;49msuggest_next_locations()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# Simulate experiments at the suggested locations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grantdidway/Documents/summer23/OT2Control/gp_test_shahrom.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     Y_new \u001b[39m=\u001b[39m simulate_chemistry(next_locations)\n",
      "File \u001b[0;32m~/Documents/summer23/OT2Control/ml_models.py:279\u001b[0m, in \u001b[0;36mOptimizationModel.suggest_next_locations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_acquisition()\n\u001b[1;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m GPyOpt\u001b[39m.\u001b[39mmethods\u001b[39m.\u001b[39mModularBayesianOptimization(\n\u001b[1;32m    277\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspace, \u001b[39mNone\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macquisition, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator, np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment_data[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment_data[\u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49msuggest_next_locations()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPyOpt/core/bo.py:67\u001b[0m, in \u001b[0;36mBO.suggest_next_locations\u001b[0;34m(self, context, pending_X, ignored_X)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_acquisitions \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext \u001b[39m=\u001b[39m context\n\u001b[0;32m---> 67\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalization_type)\n\u001b[1;32m     69\u001b[0m suggested_locations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_next_evaluations(pending_zipped_X \u001b[39m=\u001b[39m pending_X, ignored_zipped_X \u001b[39m=\u001b[39m ignored_X)\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m suggested_locations\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPyOpt/core/bo.py:253\u001b[0m, in \u001b[0;36mBO._update_model\u001b[0;34m(self, normalization_type)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         Y_inmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mupdateModel(X_inmodel, Y_inmodel, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    255\u001b[0m \u001b[39m# Save parameters of the model\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_model_parameter_values()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPyOpt/models/gpmodel.py:83\u001b[0m, in \u001b[0;36mGPModel.updateModel\u001b[0;34m(self, X_all, Y_all, X_new, Y_new)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mUpdates the model with new observations.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_model(X_all, Y_all)\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_XY(X_all, Y_all)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPyOpt/models/gpmodel.py:67\u001b[0m, in \u001b[0;36mGPModel._create_model\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     64\u001b[0m noise_var \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mvar()\u001b[39m*\u001b[39m\u001b[39m0.01\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_var\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m GPy\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mGPRegression(X, Y, kernel\u001b[39m=\u001b[39;49mkern, noise_var\u001b[39m=\u001b[39;49mnoise_var, mean_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_function)\n\u001b[1;32m     68\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m GPy\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSparseGPRegression(X, Y, kernel\u001b[39m=\u001b[39mkern, num_inducing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_inducing, mean_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_function)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/paramz/parameterized.py:53\u001b[0m, in \u001b[0;36mParametersChangedMeta.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m#import ipdb;ipdb.set_trace()\u001b[39;00m\n\u001b[1;32m     52\u001b[0m initialize \u001b[39m=\u001b[39m kw\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39minitialize\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 53\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(ParametersChangedMeta, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     54\u001b[0m \u001b[39m#logger.debug(\"finished init\")\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_init_ \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPy/models/gp_regression.py:36\u001b[0m, in \u001b[0;36mGPRegression.__init__\u001b[0;34m(self, X, Y, kernel, Y_metadata, normalizer, noise_var, mean_function)\u001b[0m\n\u001b[1;32m     32\u001b[0m     kernel \u001b[39m=\u001b[39m kern\u001b[39m.\u001b[39mRBF(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m likelihood \u001b[39m=\u001b[39m likelihoods\u001b[39m.\u001b[39mGaussian(variance\u001b[39m=\u001b[39mnoise_var)\n\u001b[0;32m---> 36\u001b[0m \u001b[39msuper\u001b[39;49m(GPRegression, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(X, Y, kernel, likelihood, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGP regression\u001b[39;49m\u001b[39m'\u001b[39;49m, Y_metadata\u001b[39m=\u001b[39;49mY_metadata, normalizer\u001b[39m=\u001b[39;49mnormalizer, mean_function\u001b[39m=\u001b[39;49mmean_function)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/GPy/core/gp.py:46\u001b[0m, in \u001b[0;36mGP.__init__\u001b[0;34m(self, X, Y, kernel, likelihood, mean_function, inference_method, name, Y_metadata, normalizer)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m ObsAr(X)\n\u001b[0;32m---> 46\u001b[0m \u001b[39massert\u001b[39;00m Y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     47\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39minitializing Y\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m normalizer \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define random bounds for the variables\n",
    "bounds = [\n",
    "    {'name': 'var1', 'type': 'continuous', 'domain': (0, 10)},\n",
    "    {'name': 'var2', 'type': 'continuous', 'domain': (0, 10)},\n",
    "    {'name': 'var3', 'type': 'continuous', 'domain': (0, 10)}\n",
    "]\n",
    "\n",
    "# Define a random target value\n",
    "target_value = np.random.randint(1, 1000)\n",
    "\n",
    "# Define random reagent information\n",
    "reagent_info = {'reagent1': 20, 'reagent2': 30, 'reagent3': 25, 'reagent4': 50, 'reagent5': 15}  # Assuming volumes in μL\n",
    "\n",
    "# Define fixed reagents (randomly chosen)\n",
    "fixed_reagents = [('reagent2', 30), ('reagent3', 25), ('reagent4', 50)]  # Example fixed reagents with volumes\n",
    "\n",
    "# Initialize the optimization model\n",
    "opt_model = OptimizationModel(bounds, target_value, reagent_info, fixed_reagents, initial_design_numdata=15, batch_size=3)\n",
    "\n",
    "# Function to simulate chemistry experiments\n",
    "def simulate_chemistry(x):\n",
    "    \"\"\"\n",
    "    Simulates a chemistry experiment based on input variables x.\n",
    "    The function returns a 'result' mimicking an experimental outcome.\n",
    "    \"\"\"\n",
    "    # Simulate some arbitrary chemistry logic that relates x to an outcome\n",
    "    result = np.sum(x**2, axis=1) * np.random.uniform(0.95, 1.05, size=x.shape[0])\n",
    "    # Ensure the result is a 2D array with one column\n",
    "    return result.reshape(-1, 1)\n",
    "\n",
    "# Generate initial design and simulate experiments to get initial data\n",
    "X_initial = opt_model.generate_initial_design()\n",
    "Y_initial = simulate_chemistry(X_initial)\n",
    "\n",
    "# Initialize the optimizer with initial experimental data\n",
    "opt_model.initialize_optimizer(X_initial, Y_initial)\n",
    "\n",
    "print(opt_model.optimizer)\n",
    "print(opt_model.acquisition)\n",
    "\n",
    "\n",
    "# Learning loop\n",
    "number_of_iterations = 15  # Define the number of iterations for the learning loop\n",
    "for i in range(number_of_iterations):\n",
    "    # Suggest next locations for experiments\n",
    "    next_locations = opt_model.suggest_next_locations()\n",
    "    \n",
    "    # Simulate experiments at the suggested locations\n",
    "    Y_new = simulate_chemistry(next_locations)\n",
    "    \n",
    "    # Update the optimizer with the new experimental data\n",
    "    opt_model.update_experiment_data(next_locations, Y_new)\n",
    "    \n",
    "    print(f\"Iteration {i+1}, Suggested Locations: {next_locations}, Results: {Y_new}\")\n",
    "    \n",
    "    # Optional: Check if the optimizer has met the target or other stopping criteria\n",
    "    if opt_model.optimizer.quit:\n",
    "        print(\"Stopping criteria met.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random bounds for the variables\n",
    "bounds = [{'name': 'var1', 'type': 'continuous', 'domain': (0, 10)},\n",
    "          {'name': 'var2', 'type': 'continuous', 'domain': (0, 10)},\n",
    "          {'name': 'var3', 'type': 'continuous', 'domain': (0, 10)}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a random target value\n",
    "target_value = np.random.randint(1, 1000)\n",
    "\n",
    "# Define random reagent information\n",
    "reagent_info = {'reagent1': 20, 'reagent2': 30, 'reagent3': 25, 'reagent4': 50, 'reagent5': 15}  # Assuming volumes in μL\n",
    "\n",
    "# Define fixed reagents (randomly chosen)\n",
    "fixed_reagents = [('reagent2', 30), ('reagent3', 25), ('reagent4', 50)]  # Example fixed reagents with volumes\n",
    "\n",
    "# Initialize the optimization model\n",
    "opt_model = OptimizationModel(bounds, target_value, reagent_info, fixed_reagents)\n",
    "\n",
    "# Get initial design samples\n",
    "initial_design = opt_model.get_initial_design()\n",
    "\n",
    "# Test the model with random data\n",
    "num_tests = 5\n",
    "for i in range(num_tests):\n",
    "    # Generate random experimental data (just for demonstration purposes)\n",
    "    X_new = np.random.rand(1, len(bounds))\n",
    "    Y_new = np.random.rand()  # Random output value\n",
    "    \n",
    "    # Update the model with the new experimental data\n",
    "    opt_model.update_model(X_new, Y_new)\n",
    "    \n",
    "# Suggest the next location for experimentation\n",
    "next_location = opt_model.suggest_next_location()\n",
    "\n",
    "print(\"Initial Design:\")\n",
    "print(initial_design)\n",
    "print(\"\\nNext Location for Experimentation:\")\n",
    "print(next_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be44935fcddb7a5b39cc12a7076549386e43a478b7f2a324b7f9efaa2ae6c3ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
