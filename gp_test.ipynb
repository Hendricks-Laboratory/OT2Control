{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPyOpt\n",
    "import pandas as pd\n",
    "from ml_models import OptimizationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update experiment_data DataFrame after each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_experiment_data(self, wellnames, recipes, Experiment_result, GP_Prediction):\n",
    "    new_data = pd.DataFrame({\n",
    "        'Recipes': recipes,\n",
    "        'WellNames': wellnames, \n",
    "        'Experiment Result': Experiment_result,\n",
    "        'GP Prediction': GP_Prediction\n",
    "    })\n",
    "    self.experiment_data = pd.concat([self.experiment_data, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe we will be updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = pd.DataFrame(columns = [\"Recipes\", \"Wellnames\", \"Experiment_result\", \"GP_Prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Branin function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branin function (look up graph + equation as reference), has three global minimas. We are using it as a way to test our optimization model as we're trying to exploit/explore these global minimas using our acquisition function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branin function will behave as our objective function here. Hopefully, our GP model will learn the space of the branin function by sampling + evaluating different points (acquisition function will balance exploitation vs exploration).\n",
    "Hopefully it will find global minimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin(x):\n",
    "    # The recommended values of the parameters\n",
    "    a = 1\n",
    "    b = 5.1 / (4 * np.pi**2)\n",
    "    c = 5 / np.pi\n",
    "    r = 6\n",
    "    s = 10\n",
    "    t = 1 / (8 * np.pi)\n",
    "    # The expression of the function\n",
    "    return (a * (x[:, 1] - b * x[:, 0]**2 + c * x[:, 0] - r)**2 + s * (1 - t) * np.cos(x[:, 0]) + s).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_shaha(index):\n",
    "    return f\"shaha{index}{random.randint(0, 9999):04d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode batch_size = 5\n",
    "# hardcode y_shape to be 2 assuming we are fixing 3 reagents and varing 2 of em.\n",
    "batch_size = 5\n",
    "y_shape = 2\n",
    "def run(self, model):\n",
    "        # define variables.\n",
    "        self.batch_num = 0 \n",
    "        recipes = np.ones((batch_size, y_shape)) * 3.1415e-2\n",
    "        \n",
    "        # RUN FIRST RECIPE.\n",
    "        print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "        \n",
    "        # generate new wellnames for next batch\n",
    "        wellnames = [self.generate_shaha(i) for i in range(recipes.shape[0])]\n",
    "        \n",
    "        # Use the Branin function to generate \"scan data\"\n",
    "        scan_data = branin(recipes)\n",
    "\n",
    "        model.train(recipes, scan_data)\n",
    "                \n",
    "        self.batch_num += 1\n",
    "\n",
    "        # ENTER LOOP TO TRAIN RECIPES.\n",
    "        while not model.quit:\n",
    "            model.train(recipes, scan_data)\n",
    "            print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "            \n",
    "            # generate new wellnames for next batch\n",
    "            wellnames = [self.generate_shaha(i) for i in range(recipes.shape[0])]\n",
    "            \n",
    "            # TODO: last_filename gets in data from the create_samples sheet. Use our \"function\" to pull in fake data/replicate create_samples.\n",
    "            \n",
    "            # pull in wavelength light absorption level.\n",
    "            scan_data = ???\n",
    "            \n",
    "            # generate the predictions for the next round\n",
    "            gp_prediction = model.predict()\n",
    "            self.batch_num += 1\n",
    "            \n",
    "            # update our experiment data TODO.\n",
    "            self._update_experiment_data(wellnames, recipes, scan_data, gp_prediction)\n",
    "            recipes = gp_prediction\n",
    "            \n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run(self, port, simulate, model, no_pr):\n",
    "    '''\n",
    "    private function to run\n",
    "    '''\n",
    "    self.batch_num = 0 #used internally for unique filenames\n",
    "    self.well_count = 0 #used internally for unique wellnames\n",
    "    self._init_pr(simulate, no_pr)\n",
    "    #create a connection\n",
    "    sock = socket.socket(socket.AF_INET)\n",
    "    sock.connect((self.server_ip, port))\n",
    "    buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)\n",
    "    print(\"<<controller>> connected\")\n",
    "    self.portal = Armchair(buffered_sock,'controller','Armchair_Logs', buffsize=4)\n",
    "    self.init_robot(simulate)\n",
    "    \n",
    "    recipes = model.generate_seed_rxns()\n",
    "    recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "    \n",
    "    # expand recipes: recipes[n-1] holds num_duplicates (default value is 3).\n",
    "    # recipes = np.vstack([recipes, [self.num_duplicates]])\n",
    "\n",
    "    #do the first one\n",
    "    print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "    #don't have data to train, so, not training\n",
    "    #generate new wellnames for next batch\n",
    "    wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]\n",
    "    #plan and execute a reaction with duplicates.\n",
    "    self._create_samples(wellnames, recipes)\n",
    "    #pull in the scan data\n",
    "    filenames = self.rxn_df[\n",
    "            (self.rxn_df['op'] == 'scan') |\n",
    "            (self.rxn_df['op'] == 'scan_until_complete')\n",
    "            ].reset_index()\n",
    "    #TODO filenames is empty. dunno why\n",
    "    last_filename = filenames.loc[filenames['index'].idxmax(),'scan_filename']\n",
    "    scan_data = self._get_sample_data(wellnames, last_filename)\n",
    "    model.train(recipes, scan_data.T.to_numpy())\n",
    "    #this is different because we don't want to use untrained model to generate predictions\n",
    "    recipes = model.generate_seed_rxns()\n",
    "    recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "    self.batch_num += 1\n",
    "\n",
    "    #enter iterative while loop now that we have data\n",
    "    while not model.quit:\n",
    "        model.train(recipes, scan_data.T.to_numpy())      # temp: added experiment_result.\n",
    "        print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "        #generate new wellnames for next batch\n",
    "        wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]\n",
    "        # plan and execute a reaction with duplicate reactions.\n",
    "        self._create_samples(wellnames, recipes, self.num_duplicates)\n",
    "        #pull in the scan data\n",
    "        filenames = self.rxn_df[\n",
    "                (self.rxn_df['op'] == 'scan') |\n",
    "                (self.rxn_df['op'] == 'scan_until_complete')\n",
    "                ].reset_index()\n",
    "        last_filename = filenames.loc[filenames['index'].idxmax(),'scan_filename']\n",
    "        scan_data = self._get_sample_data(wellnames, last_filename)\n",
    "        #generate the predictions for the next round\n",
    "        gp_prediction = model.predict()     # changed from recipes, used as temp variable; refer to line 2200.\n",
    "        #threaded train on scans. Will run while the robot is generating new materials\n",
    "        self.batch_num += 1\n",
    "        # update our experiment data TODO.\n",
    "        self._update_experiment_data(wellnames, recipes, scan_data, gp_prediction)\n",
    "        recipes = gp_prediction\n",
    "        recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "        \n",
    "    self.close_connection()\n",
    "    self.pr.shutdown()\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be44935fcddb7a5b39cc12a7076549386e43a478b7f2a324b7f9efaa2ae6c3ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
