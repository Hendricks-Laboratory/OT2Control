{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPyOpt\n",
    "import pandas as pd\n",
    "from ml_models import OptimizationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update experiment_data DataFrame after each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_experiment_data(self, wellnames, recipes, Experiment_result, GP_Prediction):\n",
    "    new_data = pd.DataFrame({\n",
    "        'Recipes': recipes,\n",
    "        'WellNames': wellnames, \n",
    "        'Experiment Result': Experiment_result,\n",
    "        'GP Prediction': GP_Prediction\n",
    "    })\n",
    "    self.experiment_data = pd.concat([self.experiment_data, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe we will be updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = pd.DataFrame(columns = [\"Recipes\", \"Wellnames\", \"Experiment_result\", \"GP_Prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Branin function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branin function (look up graph + equation as reference), has three global minimas. We are using it as a way to test our optimization model as we're trying to exploit/explore these global minimas using our acquisition function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branin function will behave as our objective function here. Hopefully, our GP model will learn the space of the branin function by sampling + evaluating different points (acquisition function will balance exploitation vs exploration).\n",
    "Hopefully it will find global minimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin(x):\n",
    "    # The recommended values of the parameters\n",
    "    a = 1\n",
    "    b = 5.1 / (4 * np.pi**2)\n",
    "    c = 5 / np.pi\n",
    "    r = 6\n",
    "    s = 10\n",
    "    t = 1 / (8 * np.pi)\n",
    "    # The expression of the function\n",
    "    return (a * (x[:, 1] - b * x[:, 0]**2 + c * x[:, 0] - r)**2 + s * (1 - t) * np.cos(x[:, 0]) + s).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_shaha(index):\n",
    "    return f\"shaha{index}{random.randint(0, 9999):04d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode batch_size = 5\n",
    "# hardcode y_shape to be 2 assuming we are fixing 3 reagents and varing 2 of em.\n",
    "batch_size = 5\n",
    "y_shape = 2\n",
    "def run(self, model):\n",
    "        # define variables.\n",
    "        self.batch_num = 0 \n",
    "        recipes = np.ones((batch_size, y_shape)) * 3.1415e-2\n",
    "        \n",
    "        # RUN FIRST RECIPE.\n",
    "        print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "        \n",
    "        # generate new wellnames for next batch\n",
    "        wellnames = [self.generate_shaha(i) for i in range(recipes.shape[0])]\n",
    "        \n",
    "        # Use the Branin function to generate \"scan data\"\n",
    "        scan_data = branin(recipes)\n",
    "\n",
    "        model.train(recipes, scan_data)\n",
    "                \n",
    "        self.batch_num += 1\n",
    "\n",
    "        # ENTER LOOP TO TRAIN RECIPES.\n",
    "        while not model.quit:\n",
    "            model.train(recipes, scan_data)\n",
    "            print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "            \n",
    "            # generate new wellnames for next batch\n",
    "            wellnames = [self.generate_shaha(i) for i in range(recipes.shape[0])]\n",
    "            \n",
    "            # TODO: last_filename gets in data from the create_samples sheet. Use our \"function\" to pull in fake data/replicate create_samples.\n",
    "            \n",
    "            # pull in wavelength light absorption level.\n",
    "            scan_data = ???\n",
    "            \n",
    "            # generate the predictions for the next round\n",
    "            gp_prediction = model.predict()\n",
    "            self.batch_num += 1\n",
    "            \n",
    "            # update our experiment data TODO.\n",
    "            self._update_experiment_data(wellnames, recipes, scan_data, gp_prediction)\n",
    "            recipes = gp_prediction\n",
    "            \n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_auto(serveraddr, rxn_sheet_name, use_cache, simulate, no_sim, no_pr):\n",
    "    '''\n",
    "    main function to launch an auto scientist that designs it's own experiments\n",
    "    '''\n",
    "    if not rxn_sheet_name:\n",
    "        rxn_sheet_name = input('<<controller>> please input the sheet name ')\n",
    "    my_ip = socket.gethostbyname(socket.gethostname())\n",
    "    auto = AutoContr(rxn_sheet_name, my_ip, serveraddr, use_cache=use_cache)\n",
    "    #note shorter iterations for testing\n",
    "    final_spectra = np.loadtxt(\n",
    "            \"test_target_1.csv\", delimiter=',', dtype=float).reshape(1,-1)\n",
    "    print(auto.rxn_df.describe())\n",
    "    print(auto.rxn_df.head(20))\n",
    "    print(auto.rxn_df)\n",
    "    y_shape = auto.y_shape# number of reagents to learn on\n",
    "    print(\"starting with y_shape:\", y_shape)\n",
    "    reagent_info = auto.robo_params['reagent_df']\n",
    "    # Generate bounds for each reagent, assuming concentrations range from 0 to 1\n",
    "    bounds = [{'name': f'reagent_{i+1}_conc', 'type': 'continuous', 'domain': (0, 1)} for i in range(y_shape)]\n",
    "    #TODO get reagent info\n",
    "    model = OptimizationModel(bounds, final_spectra, reagent_info, fixed_reagents)\n",
    "    if not no_sim:\n",
    "        auto.run_simulation(no_pr=no_pr)\n",
    "    if input('would you like to run on robot and pr? [yn] ').lower() == 'y':\n",
    "        auto.run_protocol(simulate=simulate, model=model,no_pr=no_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(self,model=None,no_pr=False):\n",
    "    '''\n",
    "    runs a full simulation of the protocol on local machine\n",
    "    Temporarilly overwrites the self.server_ip with loopback, but will restore it at\n",
    "    end of function  \n",
    "    params:\n",
    "        MLModel model: the model to use when training and predicting  \n",
    "    Returns:  \n",
    "        bool: True if all tests were passed  \n",
    "    '''\n",
    "    #cache some things before you overwrite them for the simulation\n",
    "    stored_server_ip = self.server_ip\n",
    "    stored_simulate = self.simulate\n",
    "    self.server_ip = '127.0.0.1'\n",
    "    self.simulate = True\n",
    "    if model == None:\n",
    "        #you're simulating with a dummy model.\n",
    "        print('<<controller>> running with dummy ml')\n",
    "        model = DummyMLModel(self.reagent_order.shape[0], max_iters=2)\n",
    "    print('<<controller>> ENTERING SIMULATION')\n",
    "    port = 50000\n",
    "    #launch an eve server in background for simulation purposes\n",
    "    b = threading.Barrier(2,timeout=20)\n",
    "    eve_thread = threading.Thread(target=launch_eve_server, kwargs={'my_ip':'','barrier':b},name='eve_thread')\n",
    "    eve_thread.start()\n",
    "    #do create a connection\n",
    "    b.wait()\n",
    "    self._run(port, True, model, no_pr)\n",
    "\n",
    "    #collect the eve thread\n",
    "    eve_thread.join()\n",
    "\n",
    "    #restore changed vars\n",
    "    self.server_ip = stored_server_ip\n",
    "    self.simulate = stored_simulate\n",
    "    print('<<controller>> EXITING SIMULATION')\n",
    "    return True\n",
    "\n",
    "def run_protocol(self, model=None, simulate=False, port=50000, no_pr=False):\n",
    "    '''\n",
    "    The real deal. Input a server addr and port if you choose and protocol will be run  \n",
    "    params:  \n",
    "        str simulate: (this should never be used in normal operation. It is for debugging\n",
    "            on the robot)  \n",
    "        bool no_pr: if True, will not use the plate reader even if possible to simulate\n",
    "        MLModel model: the model to use when training and predicting  \n",
    "    NOTE: the simulate here is a little different than running run_simulation(). This simulate\n",
    "        is sent to the robot to tell it to simulate the reaction, but that it all. The other\n",
    "        simulate changes some things about how code is run from the controller\n",
    "    '''\n",
    "    print('<<controller>> RUNNING')\n",
    "    if model == None:\n",
    "        #you're simulating with a dummy model.\n",
    "        print('<<controller>> running with dummy ml')\n",
    "        model = DummyMLModel(self.reagent_order.shape[0], max_iters=2)\n",
    "    self._run(port, simulate, model, no_pr)\n",
    "    print('<<controller>> EXITING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run(self, port, simulate, model, no_pr):\n",
    "    '''\n",
    "    private function to run\n",
    "    '''\n",
    "    self.batch_num = 0 #used internally for unique filenames\n",
    "    self.well_count = 0 #used internally for unique wellnames\n",
    "    self._init_pr(simulate, no_pr)\n",
    "    #create a connection\n",
    "    sock = socket.socket(socket.AF_INET)\n",
    "    sock.connect((self.server_ip, port))\n",
    "    buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)\n",
    "    print(\"<<controller>> connected\")\n",
    "    self.portal = Armchair(buffered_sock,'controller','Armchair_Logs', buffsize=4)\n",
    "    self.init_robot(simulate)\n",
    "    \n",
    "    recipes = model.generate_seed_rxns()\n",
    "    recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "    \n",
    "    # expand recipes: recipes[n-1] holds num_duplicates (default value is 3).\n",
    "    # recipes = np.vstack([recipes, [self.num_duplicates]])\n",
    "\n",
    "    #do the first one\n",
    "    print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "    #don't have data to train, so, not training\n",
    "    #generate new wellnames for next batch\n",
    "    wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]\n",
    "    #plan and execute a reaction with duplicates.\n",
    "    self._create_samples(wellnames, recipes)\n",
    "    #pull in the scan data\n",
    "    filenames = self.rxn_df[\n",
    "            (self.rxn_df['op'] == 'scan') |\n",
    "            (self.rxn_df['op'] == 'scan_until_complete')\n",
    "            ].reset_index()\n",
    "    #TODO filenames is empty. dunno why\n",
    "    last_filename = filenames.loc[filenames['index'].idxmax(),'scan_filename']\n",
    "    scan_data = self._get_sample_data(wellnames, last_filename)\n",
    "    model.train(recipes, scan_data.T.to_numpy())\n",
    "    #this is different because we don't want to use untrained model to generate predictions\n",
    "    recipes = model.generate_seed_rxns()\n",
    "    recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "    self.batch_num += 1\n",
    "\n",
    "    #enter iterative while loop now that we have data\n",
    "    while not model.quit:\n",
    "        model.train(recipes, scan_data.T.to_numpy())      # temp: added experiment_result.\n",
    "        print('<<controller>> executing batch {}'.format(self.batch_num))\n",
    "        #generate new wellnames for next batch\n",
    "        wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]\n",
    "        # plan and execute a reaction with duplicate reactions.\n",
    "        self._create_samples(wellnames, recipes, self.num_duplicates)\n",
    "        #pull in the scan data\n",
    "        filenames = self.rxn_df[\n",
    "                (self.rxn_df['op'] == 'scan') |\n",
    "                (self.rxn_df['op'] == 'scan_until_complete')\n",
    "                ].reset_index()\n",
    "        last_filename = filenames.loc[filenames['index'].idxmax(),'scan_filename']\n",
    "        scan_data = self._get_sample_data(wellnames, last_filename)\n",
    "        #generate the predictions for the next round\n",
    "        gp_prediction = model.predict()     # changed from recipes, used as temp variable; refer to line 2200.\n",
    "        #threaded train on scans. Will run while the robot is generating new materials\n",
    "        self.batch_num += 1\n",
    "        # update our experiment data TODO.\n",
    "        self._update_experiment_data(wellnames, recipes, scan_data, gp_prediction)\n",
    "        recipes = gp_prediction\n",
    "        recipes =  self.duplicate_list_elements(recipes, self.num_duplicates)     \n",
    "        \n",
    "    self.close_connection()\n",
    "    self.pr.shutdown()\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be44935fcddb7a5b39cc12a7076549386e43a478b7f2a324b7f9efaa2ae6c3ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
